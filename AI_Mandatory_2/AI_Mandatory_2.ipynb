{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IN3050/IN4050 Mandatory Assignment 2, 2022: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules\n",
    "\n",
    "Before you begin the exercise, review the rules at this website: https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-mandatory.html , in particular the paragraph on cooperation. This is an individual assignment. You are not allowed to deliver together or copy/share source-code/answers with others. By submitting this assignment, you confirm that you are familiar with the rules and the consequences of breaking them.\n",
    "\n",
    "### Delivery\n",
    "\n",
    "**Deadline**: Friday, March 25, 2022, 23:59\n",
    "\n",
    "Your submission should be delivered in Devilry. You may redeliver in Devilry before the deadline, but include all files in the last delivery, as only the last delivery will be read. You are recommended to upload preliminary versions hours (or days) before the final deadline.\n",
    "\n",
    "### What to deliver?\n",
    "\n",
    "You are recommended to solve the exercise in a Jupyter notebook, but you might solve it in a Python program if you prefer.\n",
    "\n",
    "If you choose Jupyter, you should deliver the notebook. You should answer all questions and explain what you are doing in Markdown. Still, the code should be properly commented. The notebook should contain results of your runs. In addition, you should make a pdf of your solution which shows the results of the runs. (If you can't export: notebook -> latex -> pdf on your own machine, you may do this on the IFI linux machines.)\n",
    "\n",
    "If you prefer not to use notebooks, you should deliver the code, your run results, and a pdf-report where you answer all the questions and explain your work.\n",
    "\n",
    "Your report/notebook should contain your name and username.\n",
    "\n",
    "Deliver one single zipped folder (.zip, .tgz or .tar.gz) which contains your complete solution.\n",
    "\n",
    "Important: if you weren’t able to finish the assignment, use the PDF report/Markdown to elaborate on what you’ve tried and what problems you encountered. Students who have made an effort and attempted all parts of the assignment will get a second chance even if they fail initially. This exercise will be graded PASS/FAIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of the assignment\n",
    "The goal of this assignment is to get a better understanding of supervised learning with gradient descent. It will, in particular, consider the similarities and differences between linear classifiers and multi-layer feed forward networks (multi-layer perceptron, MLP) and the differences and similarities between binary and multi-class classification. A main part will be dedicated to implementing and understanding the backpropagation algorithm. \n",
    "\n",
    "### Tools\n",
    "The aim of the exercises is to give you a look inside the learning algorithms. You may freely use code from the weekly exercises and the published solutions. You should not use ML libraries like scikit-learn or tensorflow.\n",
    "\n",
    "You may use tools like NumPy and Pandas, which are not specific ML-tools.\n",
    "\n",
    "The given precode uses NumPy. You are recommended to use NumPy since it results in more compact code, but feel free to use pure python if you prefer. \n",
    "\n",
    "### Beware\n",
    "There might occur typos or ambiguities. This is a revised assignment compared to earlier years, and there might be new typos. If anything is unclear, do not hesitate to ask. Also, if you think some assumptions are missing, make your own and explain them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import sklearn  #for datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear classifiers\n",
    "## Datasets\n",
    "We start by making a synthetic dataset of 2000 datapoints and five classes, with 400 individuals in each class. (See https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html regarding how the data are generated.) We choose to use a synthetic dataset---and not a set of natural occuring data---because we are mostly interested in properties of the various learning algorithms, in particular the differences between linear classifiers and multi-layer neural networks together with the difference between binary and multi-class data.\n",
    "\n",
    "When we are doing experiments in supervised learning, and the data are not already split into training and test sets, we should start by splitting the data. Sometimes there are natural ways to split the data, say training on data from one year and testing on data from a later year, but if that is not the case, we should shuffle the data randomly before splitting. (OK, that is not necessary with this particular synthetic data set, since it is already shuffled by default by scikit, but that will not be the case with real-world data.) We should split the data so that we keep the alignment between X and t, which may be achieved by shuffling the indices. We split into 50% for training, 25% for validation, and 25% for final testing. The set for final testing *must not be used* till the end of the assignment in part 3.\n",
    "\n",
    "We fix the seed both for data set generation and for shuffling, so that we work on the same datasets when we rerun the experiments. This is done by the `random_state` argument and the `rng = np.random.RandomState(2022)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, t = make_blobs(n_samples=[400, 400, 400, 400, 400], centers=[[0, 1], [4, 1], [8, 1], [2, 0], [6, 0]],\n",
    "                  n_features=2, random_state=2022, cluster_std=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(X.shape[0])\n",
    "rng = np.random.RandomState(2022)\n",
    "rng.shuffle(indices)\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[indices[:1000], :]\n",
    "X_val = X[indices[1000:1500], :]\n",
    "X_test = X[indices[1500:], :]\n",
    "t_train = t[indices[:1000]]\n",
    "t_val = t[indices[1000:1500]]\n",
    "t_test = t[indices[1500:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will  make a second dataset by merging the two smaller classes in (X,t) and call the new set (X, t2). This will be a binary set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_train = t_train >= 3\n",
    "t2_train = t2_train.astype('int')\n",
    "t2_val = (t_val >= 3).astype('int')\n",
    "t2_test = (t_test >= 3).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the two traing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))  # You may adjust the size\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=t_train, s=20.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=t2_train, s=20.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "We see that that set (X, t2) is far from linearly separable, and we will explore how various classifiers are able to handle this. We start with linear regression. You may make your own implementation from scratch or start with the solution to the weekly exercise set 7, which we include here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    # Put bias in position 0\n",
    "    sh = X.shape\n",
    "    if len(sh) == 1:\n",
    "        #X is a vector\n",
    "        return np.concatenate([np.array([1]), X])\n",
    "    else:\n",
    "        # X is a matrix\n",
    "        m = sh[0]\n",
    "        bias = np.ones((m, 1))  # Makes a m*1 matrix of 1-s\n",
    "        return np.concatenate([bias, X], axis=1)\n",
    "\n",
    "\n",
    "def add_bias_minus_one(X):\n",
    "    # Put bias in position 0\n",
    "    sh = X.shape\n",
    "    if len(sh) == 1:\n",
    "        #X is a vector\n",
    "        return np.concatenate([np.array([-1]), X])\n",
    "    else:\n",
    "        # X is a matrix\n",
    "        m = sh[0]\n",
    "        bias = np.ones((m, 1))  # Makes a m*1 matrix of 1-s\n",
    "        bias = bias * -1\n",
    "        return np.concatenate([bias, X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyClassifier:\n",
    "    \"\"\"Common methods to all numpy classifiers --- if any\"\"\"\n",
    "\n",
    "    def accuracy(self, X_test_a, y_test_a, **kwargs):\n",
    "        pred = self.predict(X_test_a, **kwargs)\n",
    "        if len(pred.shape) > 1:\n",
    "            pred = pred[:, 0]\n",
    "        return np.sum(pred == y_test_a) / len(pred)\n",
    "\n",
    "    def predict(self, X_test_p, param):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyLinRegClass(NumpyClassifier):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_train = []\n",
    "        self.t_train = []\n",
    "        self.X_val = None\n",
    "        self.t_val = None\n",
    "        self.e = 0\n",
    "        self.mseTrainArray = []\n",
    "        self.mseValArray = []\n",
    "        self.weights = []\n",
    "        self.accuracyTrainArray = []\n",
    "        self.accuracyValArray = []\n",
    "\n",
    "    @staticmethod\n",
    "    def mse(y, y_pred):\n",
    "        sum_errors = 0.\n",
    "        for i in range(0, len(y)):\n",
    "            sum_errors += (y[i] - y_pred[i]) ** 2\n",
    "        mean_squared_error = sum_errors / len(y)\n",
    "        return mean_squared_error\n",
    "\n",
    "    def fit(self, X_train_f, t_train_f,\n",
    "            eta_f=0.1, epochs=10, loss_diff=None,\n",
    "            X_val_f=None, t_val_f=None):\n",
    "        self.e = 0\n",
    "        self.X_train = X_train_f\n",
    "        self.t_train = t_train_f\n",
    "\n",
    "        if X_val_f is not None and t_val_f is not None:\n",
    "            self.X_val = X_val_f\n",
    "            self.t_val = t_val_f\n",
    "        \"\"\"X_train is a Nxm matrix, N data points, m features\n",
    "        t_train are the targets values for training data\"\"\"\n",
    "\n",
    "        (k, m) = self.X_train.shape\n",
    "        X_train_bias = add_bias(self.X_train)\n",
    "        self.weights = np.zeros(m + 1)\n",
    "        tryWeights = self.weights.copy()\n",
    "\n",
    "        #for self.e in range(epochs):\n",
    "        while True:\n",
    "            if self.e >= epochs - 1:\n",
    "                break\n",
    "            self.e = self.e + 1\n",
    "\n",
    "            tryWeights -= eta_f / k * X_train_bias.T @ (X_train_bias @ tryWeights - self.t_train)\n",
    "            if len(self.mseTrainArray) > 1:\n",
    "                thisTrainMse = self.mse(self.t_train, self.predict(self.X_train, weights=tryWeights))\n",
    "                prevTrainMse = self.mseTrainArray[-1]\n",
    "                self.mseTrainArray.append(thisTrainMse)\n",
    "                self.accuracyTrainArray.append(self.accuracy(self.X_train, self.t_train))\n",
    "                if self.t_val is not None and self.X_val is not None:\n",
    "                    self.mseValArray.append(self.mse(self.t_val, self.predict(self.X_val, weights=tryWeights)))\n",
    "                    self.accuracyValArray.append(self.accuracy(self.X_val, self.t_val))\n",
    "                if prevTrainMse > thisTrainMse:\n",
    "                    difference = prevTrainMse - thisTrainMse\n",
    "                    if difference > loss_diff:\n",
    "                        self.weights = tryWeights.copy()\n",
    "                    else:\n",
    "                        break\n",
    "            else:\n",
    "                self.mseTrainArray.append(self.mse(self.t_train, self.predict(self.X_train, weights=tryWeights)))\n",
    "                if self.t_val is not None and self.X_val is not None:\n",
    "                    self.mseValArray.append(self.mse(self.t_val, self.predict(self.X_val, weights=tryWeights)))\n",
    "        self.e += 1\n",
    "\n",
    "    def predict(self, x, threshold=0.5, weights=None):\n",
    "        z = add_bias(x)\n",
    "\n",
    "        if weights is None:\n",
    "            weights = self.weights\n",
    "\n",
    "        score = z @ weights\n",
    "        return score > threshold\n",
    "\n",
    "    def confusionMatrix(self, X_c, t_c):\n",
    "        prediction = self.predict(X_c)\n",
    "\n",
    "        cm = np.zeros((2, 2))\n",
    "\n",
    "        for index in range(2):\n",
    "            for j in range(2):\n",
    "                cm[index, j] = np.sum(np.where(prediction == index, 1, 0) * np.where(t_c == j, 1, 0))\n",
    "\n",
    "        return cm\n",
    "\n",
    "    def printStats(self):\n",
    "        mseFig, mseAx = plt.subplots(1)\n",
    "        accuracyFig, accuracyAx = plt.subplots(1)\n",
    "\n",
    "        print(\"Number of epochs -> \" + str(self.e))\n",
    "        mseAx.title.set_text(\"MSE Plot\")\n",
    "        accuracyAx.title.set_text(\"Accuracy Plot\")\n",
    "\n",
    "        accuracyAx.plot(range(0, len(self.accuracyTrainArray)), self.accuracyTrainArray, label=\"Training set\")\n",
    "        mseAx.plot(range(0, len(self.mseTrainArray)), self.mseTrainArray, label=\"Training set\")\n",
    "\n",
    "        if self.t_val is not None and self.X_val is not None:\n",
    "            mseAx.plot(range(0, len(self.mseValArray)), self.mseValArray, label=\"Valuation set\")\n",
    "            accuracyAx.plot(range(0, len(self.accuracyValArray)), self.accuracyValArray, label=\"Valuation set\")\n",
    "\n",
    "        mseAx.legend(loc=\"upper right\")\n",
    "        accuracyAx.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [1, 2, 5, 10, 50, 100, 1000, 10000, 100000]:\n",
    "    cl = NumpyLinRegClass()\n",
    "    # if you remove loss_diff it works much better\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, loss_diff=0.00001,\n",
    "           epochs=e, X_val_f=X_val, t_val_f=t2_val)\n",
    "    print(\"epochs -> \" + str(e))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    cl = NumpyLinRegClass()\n",
    "    # if you remove loss_diff it works much better\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=eta, loss_diff=0.00001,\n",
    "           epochs=1000, X_val_f=X_val, t_val_f=t2_val)\n",
    "    print(\"eta -> \" + str(eta))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss_diff in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    cl = NumpyLinRegClass()\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, loss_diff=loss_diff,\n",
    "           epochs=1000, X_val_f=X_val, t_val_f=t2_val)\n",
    "    print(\"loss_diff -> \" + str(loss_diff))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"epochs -> \" + str(cl.e))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NumpyLinRegClass()\n",
    "cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, loss_diff=0.0001,\n",
    "       epochs=1000, X_val_f=X_val, t_val_f=t2_val)\n",
    "cl.printStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**<br>\n",
    "MSE and Accuracy are proportional inverse. Training and validation sets follow the same pattern.\n",
    "Training set has the better statistic because our classifier is trained on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is far from impressive. Experiment with various settings for the hyper-parameters, eta and epochs. Report how the accuracy vary with the hyper-parameter settings. When you are satisfied with the result, you may plot the decision boundaries, as below.\n",
    "\n",
    "Feel free to improve the colors and the rest av of the graphics. We have chosen a simple set-up which can be applied to more than two classes without substanial modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X_p, t_p, clf, size=(8, 6)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X_p[:, 0].min() - 1, X_p[:, 0].max() + 1\n",
    "    y_min, y_max = X_p[:, 1].min() - 1, X_p[:, 1].max() + 1\n",
    "    h = 0.02  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    plt.figure(figsize=size)  # You may adjust this\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.2, cmap='Paired')\n",
    "\n",
    "    plt.scatter(X_p[:, 0], X_p[:, 1], c=t_p, s=20.0, cmap='Paired')\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"Decision regions\")\n",
    "    plt.xlabel(\"x0\")\n",
    "    plt.ylabel(\"x1\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train, t2_train, cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "The linear regression classifier is trained with mean squared error loss. So far, we have not calculated the loss explicitly in the code. Extend the code to calculate the loss on the training set for each epoch and to store the losses such that the losses can be inspected after training. \n",
    "\n",
    "Train a classifier with your best settings from last point. After training, plot the loss as a function of the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control training\n",
    "The training runs for a number of epochs. We cannot know beforehand for how many epochs it is reasonable to run the training. One possibility is to run the training until the learning does not improve much. Extend the fit-method with a keyword argument, `loss_diff`, and stop training when the loss has not improved with more than loss_diff. Also add an attribute to the classifier which tells us after fitting how many epochs were ran.\n",
    "\n",
    "In addition, extend the fit-method with optional arguments for a validation set (X_val, t_val). If a validation set is included in the call to fit, calculate the loss for the validation set, and the accuracy for both the training set and the validation set for each epoch.\n",
    "\n",
    "Train classifiers with the best value for learning rate so far, and with varying values for `loss_diff`. For each run report, `loss_diff`, accuracy and number of epochs ran.\n",
    "\n",
    "After a succesful training, plot both training loss snd vslidation loss as functions of the number of epochs in one figure, and both accuracies as functions of the number of epochs in another figure. Comment on what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "You should now do similarly for a logistic regression classifier. Calculate loss and accuracy for training set and, when provided, also for validation set.\n",
    "\n",
    "Remember that logistic regression is trained with cross-entropy loss. Hence the loss function is calculated differently than for linear regression.\n",
    "\n",
    "After a succesful training, plot both losses as functions of the number of epochs in one figure, and both accuracies as functions of the number of epochs in another figure. \n",
    "\n",
    "Comment on what you see. Do you see any differences between the linear regression classifier and the logistic regression classifier on this dataset?\n",
    "\n",
    "#### Starting point: Code from weekly 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyLogReg(NumpyClassifier):\n",
    "    def __init__(self):\n",
    "        self.eta = 0\n",
    "\n",
    "        self.celTrainArray = []\n",
    "        self.trainWeights = []\n",
    "\n",
    "        self.celValArray = []\n",
    "        self.valWeights = []\n",
    "\n",
    "        self.accuracyTrainArray = []\n",
    "        self.accuracyValArray = []\n",
    "\n",
    "        self.e = 0\n",
    "\n",
    "        self.t_val = None\n",
    "        self.X_val = None\n",
    "\n",
    "    @staticmethod\n",
    "    def cel(y, y_pred):\n",
    "        #eps should be the smallest number you can get of the float type\n",
    "        eps = np.finfo(float).eps\n",
    "        loss = -np.sum(y * np.log(y_pred + eps))\n",
    "        return loss / float(y_pred.shape[0])\n",
    "\n",
    "    def fit(self, X_train_f, t_train_f, eta_f=0.1, epochs=10, X_val_f=None, t_val_f=None):\n",
    "        \"\"\"X_train is a Nxm matrix, N data points, m features\n",
    "        t_train are the targets values for training data\"\"\"\n",
    "\n",
    "        (k, m) = X_train_f.shape\n",
    "        X_train_bias = add_bias(X_train_f)\n",
    "\n",
    "        X_val_bias = None\n",
    "        if X_val_f is not None and t_val_f is not None:\n",
    "            self.X_val = X_val_f\n",
    "            self.t_val = t_val_f\n",
    "            self.valWeights = np.zeros(m + 1)\n",
    "            X_val_bias = add_bias(X_val_f)\n",
    "\n",
    "        self.trainWeights = np.zeros(m + 1)\n",
    "        self.eta = eta_f\n",
    "        for self.e in range(epochs):\n",
    "            self.trainWeights -= eta_f / k * X_train_bias.T @ (\n",
    "                    self.forward(X_train_bias, weights=self.trainWeights) - t_train_f)\n",
    "            self.celTrainArray.append(self.cel(t_train_f, self.predict(X_train_f, weights=self.trainWeights)))\n",
    "            self.accuracyTrainArray.append(self.accuracy(X_train_f, t_train_f, weights=self.trainWeights))\n",
    "\n",
    "            if X_val_f is not None and t_val_f is not None:\n",
    "                self.valWeights -= eta_f / k * X_val_bias.T @ (\n",
    "                        self.forward(X_val_bias, weights=self.valWeights) - t_val_f)\n",
    "                self.celValArray.append(self.cel(t_val_f, self.predict(X_val_f, weights=self.valWeights)))\n",
    "                self.accuracyValArray.append(self.accuracy(X_val_f, t_val_f, weights=self.valWeights))\n",
    "        self.e += 1\n",
    "\n",
    "    def accuracy(self, X_test_a, y_test_a, weights=None):\n",
    "\n",
    "        if weights is None:\n",
    "            weights = self.trainWeights\n",
    "\n",
    "        pred = self.predict(X_test_a, weights=weights)\n",
    "        if len(pred.shape) > 1:\n",
    "            pred = pred[:, 0]\n",
    "        return np.sum(pred == y_test_a) / len(pred)\n",
    "\n",
    "    def forward(self, X_f, weights=None):\n",
    "        if weights is None:\n",
    "            weights = self.trainWeights\n",
    "\n",
    "        return logistic(X_f @ weights)\n",
    "\n",
    "    def score(self, x, weights=None):\n",
    "        z = add_bias(x)\n",
    "        score = self.forward(z, weights)\n",
    "        return score\n",
    "\n",
    "    def predict(self, x, threshold=0.5, weights=None):\n",
    "        z = add_bias(x)\n",
    "        score = self.forward(z, weights)\n",
    "        return score > threshold\n",
    "\n",
    "    def printStats(self):\n",
    "\n",
    "        mseFig, mseAx = plt.subplots(1)\n",
    "        accuracyFig, accuracyAx = plt.subplots(1)\n",
    "\n",
    "        print(\"Number of epochs -> \" + str(self.e))\n",
    "        mseAx.title.set_text(\"MSE Plot\")\n",
    "        accuracyAx.title.set_text(\"Accuracy Plot\")\n",
    "\n",
    "        accuracyAx.plot(range(0, len(self.accuracyTrainArray)), self.accuracyTrainArray, label=\"Training set\")\n",
    "        mseAx.plot(range(0, len(self.celTrainArray)), self.celTrainArray, label=\"Training set\")\n",
    "\n",
    "        if self.t_val is not None and self.X_val is not None:\n",
    "            mseAx.plot(range(0, len(self.celValArray)), self.celValArray, label=\"Valuation set\")\n",
    "            accuracyAx.plot(range(0, len(self.accuracyValArray)), self.accuracyValArray, label=\"Valuation set\")\n",
    "\n",
    "        mseAx.legend(loc=\"upper right\")\n",
    "        accuracyAx.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [1, 2, 5, 10, 50, 100, 1000, 10000, 100000]:\n",
    "    cl = NumpyLogReg()\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01,\n",
    "           epochs=e, X_val_f=X_val, t_val_f=t2_val)\n",
    "    print(\"epochs -> \" + str(e))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    cl = NumpyLogReg()\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=eta,\n",
    "           epochs=1000, X_val_f=X_val, t_val_f=t2_val)\n",
    "    print(\"eta -> \" + str(eta))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NumpyLogReg()\n",
    "cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01,\n",
    "       epochs=1000, X_val_f=X_val, t_val_f=t2_val)\n",
    "print(cl.accuracy(X_train, t2_train))\n",
    "cl.printStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**<br>\n",
    "As it was before, the training set shows the best results.\n",
    "We can also see a small improvement from before, around 5% in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classifiers\n",
    "We turn to the task of classifying when there are more than two classes, and the task is to ascribe one class to each input. We will now use the set (X, t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"One-vs-rest\" with logistic regression\n",
    "We saw in the lecture how a logistic regression classifier can be turned into a multi-class classifier using the one-vs-rest approach. We train one logistic regression classifier for each class. To predict the class of an item, we run all the binary classifiers and collect the probability score from each of them. We assign the class which ascribes the highest probability.\n",
    "\n",
    "Build such a classifier. Train the resulting classifier on (X_train, t_train), test it on (X_val, t_val), tune the hyper-parameters and report the accuracy.\n",
    "\n",
    "Also plot the decision boundaries for your best classifier similarly to the plots for the binary case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneVsRestClass(NumpyClassifier):\n",
    "    def __init__(self):\n",
    "        self.weights = []\n",
    "        self.celTrainArray = []\n",
    "\n",
    "        self.X_train = None\n",
    "        self.t_train = None\n",
    "\n",
    "    def forward(self, X_f, weights=None):\n",
    "        if weights is None:\n",
    "            weights = self.weights\n",
    "\n",
    "        return logistic(X_f @ weights)\n",
    "\n",
    "    def score(self, x, weights=None):\n",
    "        z = add_bias(x)\n",
    "        score = self.forward(z, weights)\n",
    "        return score\n",
    "\n",
    "    def predict(self, x, nLabels, threshold=0.5, weights=None):\n",
    "        z = add_bias(x)\n",
    "        if weights is None:\n",
    "            weights = self.weights\n",
    "\n",
    "        scores = np.zeros((len(x), nLabels))\n",
    "\n",
    "        for i in range(0, len(weights)):\n",
    "            scores[:, i] = self.forward(z, weights[i])\n",
    "        predict = np.zeros(len(scores))\n",
    "        for i in range(0, len(scores)):\n",
    "            predict[i] = np.argmax(scores[i])\n",
    "        return predict\n",
    "\n",
    "    def accuracy(self, X_test_a, y_test_a, weights=None):\n",
    "        pred = self.predict(X_test_a, len(np.unique(y_test_a)), weights=weights)\n",
    "        if len(pred.shape) > 1:\n",
    "            pred = pred[:, 0]\n",
    "        return np.sum(pred == y_test_a) / len(pred)\n",
    "\n",
    "    def fit(self, X_train_f, t_train_f, epochs, eta_f):\n",
    "        self.X_train = X_train_f\n",
    "        self.t_train = t_train_f\n",
    "\n",
    "        (k, m) = self.X_train.shape\n",
    "        X_train_bias_f = add_bias(self.X_train)\n",
    "        self.weights = np.zeros((len(np.unique(self.t_train)), (m + 1)))\n",
    "\n",
    "        for e in range(0, epochs):\n",
    "            self.celTrainArray.append([])\n",
    "            for i in range(0, len(np.unique(self.t_train))):\n",
    "                t_train_of_i = self.t_train == i\n",
    "                self.weights[i] -= eta_f / k * X_train_bias_f.T @ (\n",
    "                        self.forward(X_train_bias_f, weights=self.weights[i]) - t_train_of_i)\n",
    "\n",
    "    def printStats(self, size=(8, 6)):\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        x_min, x_max = self.X_train[:, 0].min() - 1, self.X_train[:, 0].max() + 1\n",
    "        y_min, y_max = self.X_train[:, 1].min() - 1, self.X_train[:, 1].max() + 1\n",
    "        h = 0.02  # step size in the mesh\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "        Z = self.predict(np.c_[xx.ravel(), yy.ravel()], len(np.unique(self.t_train)), weights=self.weights)\n",
    "\n",
    "        plt.figure(figsize=size)  # You may adjust this\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, Z, alpha=0.2, cmap='Paired')\n",
    "\n",
    "        plt.scatter(self.X_train[:, 0], self.X_train[:, 1], c=self.t_train, s=20.0, cmap='Paired')\n",
    "\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        accuracy = self.accuracy(self.X_train, self.t_train)\n",
    "        plt.title(\"Accuracy -> \" + str(accuracy) + \"\\n\\nDecision regions\")\n",
    "        plt.xlabel(\"x0\")\n",
    "        plt.ylabel(\"x1\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [1, 2, 10, 50, 100, 1000, 10000, 15000, 50000]:\n",
    "    cl = OneVsRestClass()\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, epochs=e)\n",
    "    print(\"epochs -> \" + str(e))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    cl = OneVsRestClass()\n",
    "    cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=eta, epochs=1000)\n",
    "    print(\"eta -> \" + str(eta))\n",
    "    print(\"accuracy -> \" + str(cl.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = OneVsRestClass()\n",
    "cl.fit(X_val, t_val, 15000, 0.01)\n",
    "cl.printStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For in4050-students: Multi-nominal logistic regression\n",
    "The following part is only mandatory for in4050-students. In3050-students are also welcome to make it a try. Everybody has to return for the part 2 on multi-layer neural networks. \n",
    "\n",
    "In the lecture, we contrasted the one-vs-rest approach with the multinomial logistic regression, also called softmax classifier. Implement also this classifier, tune the parameters, and compare the results to the one-vs-rest classifier. (Don't expect a large difference on a simple task like this.)\n",
    "\n",
    "Remember that this classifier uses exponetiation followed by softmax in the forward phase. For loss, it uses cross-entropy loss. The loss has a somewhat simpler form than in the binary case. To calculate the gradient is a little more complicated. The actual gradient and update rule is simple, however, as long as you have calculated the forward values correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "## Multi-layer neural networks\n",
    "We will implement the Multi-layer feed forward network (MLP, Marsland sec. 4.2.1), where we use mean squared loss together with logistic activation in both the hidden and the last layer.\n",
    "\n",
    "Since this part is more complex, we will do it in two rounds. In the first round, we will go stepwise through the algorithm with the dataset (X, t). We will initialize the network and run a first round of training, i.e. one pass through the algorithm at p. 78 in Marsland.\n",
    "\n",
    "In the second round, we will turn this code into a more general classifier. We can train and test this on (X, t) and (X, t2), but also on other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 1: One epoch of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "First we have to scale our data. Make a standard scaler (normalizer) and scale the data. Remember, not to follow Marsland on this point. The scaler should be constructed from the training data only, but be applied both to training data and later on to validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "mu = X_train.mean(axis=0)\n",
    "sigma = X_train.std(axis=0)\n",
    "Y_train = (X_train - mu) / sigma\n",
    "Y_val = (X_val - mu) / sigma\n",
    "Y_test = (X_train - mu) / sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "We will only use one hidden layer. The number of nodes in the hidden layer will be a hyper-parameter provided by the user; let's call it *dim_hidden*. (*dim_hidden* is called *M* by Marsland.) Initially, we will set it to 3. This is a hyper-parameter where other values may give better results, and the hyper-parameter could be tuned.\n",
    "\n",
    "Another hyper-parameter set by the user, is the learning rate. We set the initial value to 0.01, but also this may need tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01  #Learning rate\n",
    "dim_hidden = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the input *X_train* (after scaling) is a matrix of dimension *P x dim_in*, where *P* is the number of training instances, and *dim_in* is the number of features in the training instances (*L* in Marsland). Hence we can read *dim_in* off from *X_train*.\n",
    "\n",
    "The target values have to be converted from simple numbers, *0, 2, ...* to \"one-hot-encoded\" vectors similarly to the multi-class task. After the conversion, we can read *dim_out* off from *t_train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[indices[:1000], :]\n",
    "X_val = X[indices[1000:1500], :]\n",
    "X_test = X[indices[1500:], :]\n",
    "t_train = t[indices[:1000]]\n",
    "t_val = t[indices[1000:1500]]\n",
    "t_test = t[indices[1500:]]\n",
    "\n",
    "# convert t_train\n",
    "values_of_t = len(np.unique(t_train))\n",
    "t_train_encoded = np.zeros((len(t_train), values_of_t))\n",
    "\n",
    "for i in range(0, len(t_train)):\n",
    "    t_train_encoded[i][t_train[i]] = 1\n",
    "\n",
    "t_train = t_train_encoded\n",
    "\n",
    "dim_in = np.shape(Y_train)[1]  #len(Y_train[0])  # Calculate the correct value from the input data\n",
    "dim_out = np.shape(t_train)[1]  #len(t_train[0])  # Calculate the correct value from the input data\n",
    "\n",
    "print(dim_in)\n",
    "print(dim_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two sets of weights: weights1 between the input and the hidden layer, and weights2, between the hidden layer and the output. Make sure that you take the bias terms into consideration and get the correct dimensions. The weight matrices should be initialized to small random numbers, not to zeros. It is important that they are initialized randomly, both to ensure that different neurons start with different initial values and to generate different results when you rerun the classifier. In this introductory part, we have chosen to fix the random state to make it easier for you to control your calculations. But this should not be part of your final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2022)\n",
    "weightsInputHidden = (rng.rand(dim_in + 1, dim_hidden) * 2 - 1) / np.sqrt(dim_in)\n",
    "weightsHiddenOutput = (rng.rand(dim_hidden + 1, dim_out) * 2 - 1) / np.sqrt(dim_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weightsInputHidden.shape)\n",
    "print()\n",
    "print(weightsHiddenOutput.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwards phase\n",
    "We will run the first step in the training, and start with the forward phase. Calculate the activations after the hidden layer and after the output layer. We will follow Marsland and use the logistic (sigmoid) activation function in both layers. Inspect whether the results seem reasonable with respect to format and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bias = add_bias_minus_one(Y_train)\n",
    "print(X_train_bias)\n",
    "z_input = X_train_bias @ weightsInputHidden\n",
    "hidden_activations = logistic(z_input)\n",
    "print(hidden_activations)\n",
    "print(\"\")\n",
    "\n",
    "y_output_bias = add_bias_minus_one(hidden_activations)\n",
    "z_output = y_output_bias @ weightsHiddenOutput\n",
    "y_output = logistic(z_output)\n",
    "\n",
    "output_activations = y_output\n",
    "print(output_activations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To control that you are on the right track, you may compare your first output value with our result. We have put the bias term -1 in position 0 in both layers. If you have done anything differently from us, you will not  get the same numbers. But you may still be on the right track!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backwards phase\n",
    "Calculate the delta terms at the output. We assume, like Marsland, that we use sum of squared errors. (This amounts to the same as using the mean square error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaO = (output_activations - t_train) * output_activations * (1 - output_activations)\n",
    "print(deltaO.shape)\n",
    "eps = np.finfo(float).eps\n",
    "loss = np.sum((output_activations - t_train) ** 2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the delta terms in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weightsHiddenOutput)\n",
    "print(weightsHiddenOutput.shape)\n",
    "print(\"\")\n",
    "print(weightsInputHidden)\n",
    "deltaH = y_output_bias * (1 - y_output_bias) * (deltaO @ weightsHiddenOutput.T)\n",
    "print(deltaH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights in both layers... See whether the weights have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateHiddenInput = eta * X_train_bias.T @ deltaH[:, :-1]\n",
    "updateHiddenOutput = eta * y_output_bias.T @ deltaO\n",
    "\n",
    "weightsInputHidden = weightsInputHidden - updateHiddenInput\n",
    "weightsHiddenOutput = weightsHiddenOutput - updateHiddenOutput\n",
    "\n",
    "print(weightsInputHidden)\n",
    "print(\"\")\n",
    "print(weightsHiddenOutput)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aid, you may compare your new weights with our results. But again, you may have done everything correctly even though you get a different result. For example, there are several ways to introduce the mean squared error. They may give different results after one epoch. But if you run sufficiently many epochs, you will get about the same classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: A Multi-layer neural network classifier\n",
    "### Make the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to train and test a classifier on (X, t). You could have put some parts of the code in the last step into a loop and run it through some iterations. But instead of copying code for every network we want to train, we will build a general Multi-layer neural network classfier as a class. This class will have some of the same structure as the classifiers we made for linear and logistic regression. The task consists mainly in copying in parts from what you did in step 1 into the template below. Remember to add the *self*- prefix where needed, and be careful in your use of variable names. And don't fix the random numbers within the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, t = make_blobs(n_samples=[400, 400, 400, 400, 400], centers=[[0, 1], [4, 1], [8, 1], [2, 0], [6, 0]],\n",
    "                  n_features=2, random_state=2022, cluster_std=1.0)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "rng = np.random.RandomState(2022)\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X_train = X[indices[:1000], :]\n",
    "X_val = X[indices[1000:1500], :]\n",
    "X_test = X[indices[1500:], :]\n",
    "t_train = t[indices[:1000]]\n",
    "t_val = t[indices[1000:1500]]\n",
    "t_test = t[indices[1500:]]\n",
    "\n",
    "\n",
    "class MNNClassifier(NumpyClassifier):\n",
    "    def __init__(self, eta_i=0.001, dim_hidden_i=3):\n",
    "        \"\"\"Initialize the hyperparameters\"\"\"\n",
    "        self.eta = eta_i\n",
    "        self.dim_hidden = dim_hidden_i\n",
    "        self.X_train = None\n",
    "        self.t_train = None\n",
    "        self.t_train_not_encoded = None\n",
    "\n",
    "        self.weightsInputHidden = None\n",
    "        self.weightsHiddenOutput = None\n",
    "\n",
    "        self.dim_in = 0\n",
    "        self.dim_out = 0\n",
    "\n",
    "        self.losses = []\n",
    "\n",
    "        self.values_of_t = None\n",
    "\n",
    "        self.X_train_bias = None\n",
    "        self.y_output_bias = None\n",
    "\n",
    "    def fit(self, X_train_f, t_train_f, epochs_f=100):\n",
    "        \"\"\"Initialize the weights. Train *epochs* many epochs.\"\"\"\n",
    "\n",
    "        mu_f = X_train.mean(axis=0)\n",
    "        sigma_f = X_train.std(axis=0)\n",
    "        self.X_train = (X_train_f - mu_f) / sigma_f\n",
    "        self.t_train_not_encoded = t_train\n",
    "        self.values_of_t = len(np.unique(t_train_f))\n",
    "        t_train_encoded_f = np.zeros((len(t_train_f), self.values_of_t))\n",
    "\n",
    "        for index in range(0, len(t_train_f)):\n",
    "            t_train_encoded_f[index][t_train_f[index]] = 1\n",
    "\n",
    "        self.t_train = t_train_encoded_f\n",
    "\n",
    "        self.dim_in = np.shape(self.X_train)[1]\n",
    "        self.dim_out = np.shape(self.t_train)[1]\n",
    "\n",
    "        self.weightsInputHidden = (np.random.rand(self.dim_in + 1, self.dim_hidden) * 2 - 1) / np.sqrt(self.dim_in)\n",
    "        self.weightsHiddenOutput = (np.random.rand(self.dim_hidden + 1, self.dim_out) * 2 - 1) / np.sqrt(\n",
    "            self.dim_hidden)\n",
    "\n",
    "        for e in range(epochs_f):\n",
    "            output_activations_f = self.forward(self.X_train)\n",
    "            deltaO_f = (output_activations_f - self.t_train) * output_activations_f * (1.0 - output_activations_f)\n",
    "            self.losses.append(np.sum((output_activations_f - self.t_train) ** 2))\n",
    "            deltaH_f = self.y_output_bias * (1 - self.y_output_bias) * (deltaO_f @ self.weightsHiddenOutput.T)\n",
    "\n",
    "            updateHiddenInput_f = self.eta * self.X_train_bias.T @ deltaH_f[:, :-1]\n",
    "            updateHiddenOutput_f = self.eta * self.y_output_bias.T @ deltaO_f\n",
    "\n",
    "            self.weightsInputHidden = self.weightsInputHidden - updateHiddenInput_f\n",
    "            self.weightsHiddenOutput = self.weightsHiddenOutput - updateHiddenOutput_f\n",
    "\n",
    "    def forward(self, X_f):\n",
    "        \"\"\"Perform one forward step.\n",
    "        Return a pair consisting of the outputs of the hidden_layer\n",
    "        and the outputs on the final layer\"\"\"\n",
    "        self.X_train_bias = add_bias_minus_one(X_f)\n",
    "        z_input_f = self.X_train_bias @ self.weightsInputHidden\n",
    "        hidden_activations_f = logistic(z_input_f)\n",
    "\n",
    "        self.y_output_bias = add_bias_minus_one(hidden_activations_f)\n",
    "        z_output_f = self.y_output_bias @ self.weightsHiddenOutput\n",
    "        y_output_f = logistic(z_output_f)\n",
    "\n",
    "        output_activations_f = y_output_f\n",
    "        return output_activations_f\n",
    "\n",
    "    def predict(self, X_p, **kwargs):\n",
    "\n",
    "        X_train_bias_p = add_bias_minus_one(X_p)\n",
    "        z_input_p = X_train_bias_p @ self.weightsInputHidden\n",
    "        hidden_activations_p = logistic(z_input_p)\n",
    "        y_output_bias_p = add_bias_minus_one(hidden_activations_p)\n",
    "        z_output_f = y_output_bias_p @ self.weightsHiddenOutput\n",
    "\n",
    "        predictions_sigmoid = logistic(z_output_f)\n",
    "        predict = np.ones(len(predictions_sigmoid))\n",
    "        predict *= -1\n",
    "\n",
    "        for index in range(0, len(predictions_sigmoid)):\n",
    "            predict[index] = np.argmax(predictions_sigmoid[index])\n",
    "\n",
    "        return predict\n",
    "\n",
    "    def accuracy(self, X_test_a, t_test_a, **kwargs):\n",
    "        mu_f = X_train.mean(axis=0)\n",
    "        sigma_f = X_train.std(axis=0)\n",
    "        Y_test_a = (X_test_a - mu_f) / sigma_f\n",
    "\n",
    "        p = self.predict(Y_test_a)\n",
    "        return np.sum(p == t_test_a) / len(t_test_a)\n",
    "\n",
    "    def printStats(self):\n",
    "        plt.plot(range(0, len(self.losses)), self.losses)\n",
    "\n",
    "        t_stats = self.t_train_not_encoded\n",
    "        if self.values_of_t == 2:\n",
    "            t_stats = t_stats > 0.5\n",
    "\n",
    "        plt.title(\"Loss plot\")\n",
    "\n",
    "        plot_decision_regions(self.X_train, t_stats, self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class\n",
    "Train the network on (X_train, t_train) (after scaling), and test on (X_val, t_val). Tune the hyperparameters to get the best result:\n",
    "- number of epochs\n",
    "- learning rate\n",
    "- number of hidden nodes.\n",
    "\n",
    "When you are content with the hyperparameters, you should run the same experiment 10 times, collect the accuracies and report the mean value and standard deviation of the accuracies across the experiments. This is common practise when you apply neural networks as the result may vary slightly between the runs. You may plot the decision boundaries for one of the runs.\n",
    "\n",
    "Discuss shortly how the results and decsion boundaries compare to the \"one-vs-rest\" classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [1, 2, 10, 50, 100, 1000, 10000, 15000, 50000]:\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=3)\n",
    "    mnn.fit(X_train, t_train, epochs_f=e)\n",
    "    print(\"epochs -> \" + str(e))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    mnn = MNNClassifier(eta_i=eta, dim_hidden_i=3)\n",
    "    mnn.fit(X_train, t_train, epochs_f=100)\n",
    "    print(\"eta -> \" + str(eta))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hid in [1, 3, 6, 10, 30, 75]:\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=hid)\n",
    "    mnn.fit(X_train, t_train, epochs_f=100)\n",
    "    print(\"dim_hidden -> \" + str(hid))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for rounds in range(0, 10):\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=30)\n",
    "    mnn.fit(X_train, t_train, epochs_f=100)\n",
    "    accuracies.append(mnn.accuracy(X_val, t_val))\n",
    "\n",
    "print(\"Mean accuracy - > \" + str(np.mean(accuracies)))\n",
    "print(\"Standard deviation accuracy - > \" + str(np.std(accuracies)))\n",
    "mnn.printStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**<br>\n",
    "The difference is that in the one-vs-rest the boundaries are straight lines,\n",
    "here, instead, the boundaries could be not straight also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary class\n",
    "Let us see whether a multilayer neural network can learn a non-linear classifier.\n",
    "Train a classifier on (X_train, t2_train) and test it on (X_val, t2_val).\n",
    "Tune the hyper-parameters for the best result. Run ten times with the best setting and report mean and standard deviation. Plot the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [1, 2, 10, 50, 100, 1000, 10000, 15000, 50000]:\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=3)\n",
    "    mnn.fit(X_train, t2_train, epochs_f=e)\n",
    "    print(\"epochs -> \" + str(e))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    mnn = MNNClassifier(eta_i=eta, dim_hidden_i=3)\n",
    "    mnn.fit(X_train, t2_train, epochs_f=100)\n",
    "    print(\"eta -> \" + str(eta))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hid in [1, 3, 6, 10, 30, 75]:\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=hid)\n",
    "    mnn.fit(X_train, t2_train, epochs_f=100)\n",
    "    print(\"dim_hidden -> \" + str(hid))\n",
    "    print(\"accuracy -> \" + str(mnn.accuracy(X_val, t2_val)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for rounds in range(0, 10):\n",
    "    mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=3)\n",
    "    mnn.fit(X_train, t2_train, epochs_f=100)\n",
    "    accuracies.append(mnn.accuracy(X_val, t2_val))\n",
    "\n",
    "print(\"Mean accuracy - > \" + str(np.mean(accuracies)))\n",
    "print(\"Standard deviation accuracy - > \" + str(np.std(accuracies)))\n",
    "mnn.printStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For in4050-students: Early stopping\n",
    "The following part is only mandatory for in4050-students. In3050-students are also welcome to make it a try. Everybody has to return for the part 2 on multi-layer neural networks.\n",
    "\n",
    "There is a danger of overfitting if we run too many epochs of training. One way to control that is to use early stopping. We can use (X_val, t_val) as valuation set when training on (X_train, t_train).\n",
    "\n",
    "Let *e=50* or *e=10* (You may try both or choose some other number) After *e* number of epochs, calculate the loss for both the training set (X_train, t_train) and the validation set (X_val, t_val), and store them.\n",
    "\n",
    "Train a classifier for many epochs. Plot the losses for both the training set and the validation set in the same figure and see whether you get the same effect as in figure 4.11 in Marsland.\n",
    "\n",
    "Modify the code so that the training stops if the loss on the validation set is not reduced by more than *t* after *e* many epochs, where *t* is a threshold you provide as a parameter.\n",
    "\n",
    "Run the classifier with various values for *t* and report the accuracy and the numberof epochs ran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Final testing\n",
    "We can now perform a final testing on the held-out test set.\n",
    "\n",
    "## Binary task (X, t2)\n",
    "Consider the linear regression classifier, the logistic regression classifier and the multi-layer network with the best settings you found. Train each of them on the training set and evaluate on the held-out test set, but also on the validation set and the training set. Report in a 3 by 3 table.\n",
    "\n",
    "Comment on what you see. How do the three different algorithms compare? Also, compare the result between the different data sets. In cases like these, one might expect slightly inferior results on the held-out test data compared to the validation data. Is so the case?\n",
    "\n",
    "Also report precision and recall for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NumpyLinRegClass()\n",
    "cl.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, loss_diff=0.0001, epochs=1000)\n",
    "cl_train = cl.accuracy(X_train, t2_train)\n",
    "cl_val = cl.accuracy(X_val, t2_val)\n",
    "cl_test = cl.accuracy(X_test, t2_test)\n",
    "\n",
    "lr = NumpyLogReg()\n",
    "lr.fit(X_train_f=X_train, t_train_f=t2_train, eta_f=0.01, epochs=1000)\n",
    "lr_train = lr.accuracy(X_train, t2_train)\n",
    "lr_val = lr.accuracy(X_val, t2_val)\n",
    "lr_test = lr.accuracy(X_test, t2_test)\n",
    "\n",
    "mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=3)\n",
    "mnn.fit(X_train, t2_train, epochs_f=100)\n",
    "mnn_train = mnn.accuracy(X_train, t2_train)\n",
    "mnn_val = mnn.accuracy(X_val, t2_val)\n",
    "mnn_test = mnn.accuracy(X_test, t2_test)\n",
    "\n",
    "table_array = np.array([[\"Train\", cl_train, lr_train, mnn_train],\n",
    "                        [\"Valuate\", cl_val, lr_val, mnn_val],\n",
    "                        [\"Test\", cl_test, lr_test, mnn_test]])\n",
    "headers = [\"\", \"Linear regression\", \"Logistic regression\", \"Multi-layer neural network\"]\n",
    "table = tabulate(table_array, headers, tablefmt=\"fancy_grid\")\n",
    "print(table)\n",
    "\n",
    "confusion = cl.confusionMatrix(X_train, t2_train)\n",
    "tp = confusion[0, 0]\n",
    "fp = confusion[0, 1]\n",
    "fn = confusion[1, 0]\n",
    "tn = confusion[1, 1]\n",
    "\n",
    "print(\"Precision of Linear regression train set -> \" + str(tp / (tp + fp)))\n",
    "print(\"Recall of Linear regression train set -> \" + str(tp / (tp + fn)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**<br>\n",
    "All the data are pretty similar. In this case the test has good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class task (X, t)\n",
    "For IN3050 students compare the one-vs-rest classifier to the multi-layer preceptron. Evaluate on test, validation and training set as above. In4050-students should also include results from the multi-nomial logistic regression.\n",
    "\n",
    "Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orc = OneVsRestClass()\n",
    "orc.fit(X_val, t_val, 15000, 0.01)\n",
    "orc_train = orc.accuracy(X_train, t_train)\n",
    "orc_val = orc.accuracy(X_val, t_val)\n",
    "orc_test = orc.accuracy(X_test, t_test)\n",
    "\n",
    "mnn = MNNClassifier(eta_i=0.01, dim_hidden_i=30)\n",
    "mnn.fit(X_train, t_train, epochs_f=10000)\n",
    "mnn_train = mnn.accuracy(X_train, t_train)\n",
    "mnn_val = mnn.accuracy(X_val, t_val)\n",
    "mnn_test = mnn.accuracy(X_test, t_test)\n",
    "\n",
    "table_array = np.array([[\"Train\", orc_train, mnn_train],\n",
    "                        [\"Valuate\", orc_val, mnn_val],\n",
    "                        [\"Test\", orc_test, mnn_test]])\n",
    "\n",
    "headers = [\"\", \"One vs Rest\", \"Multi-layer neural network\"]\n",
    "table = tabulate(table_array, headers, tablefmt=\"fancy_grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**<br>\n",
    "In this case the MMN beats OvR. Also, the test set doesn't show as mush error as\n",
    "we can expect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (AI_Mandatory_2)",
   "language": "python",
   "name": "pycharm-36ddc0b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
